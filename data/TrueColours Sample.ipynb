{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9586b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdd/MSc_projects/jbarker/venvs/v_proj_1/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:42: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/mnt/sdd/MSc_projects/jbarker/venvs/v_proj_1/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:45: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/mnt/sdd/MSc_projects/jbarker/venvs/v_proj_1/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:46: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n"
     ]
    }
   ],
   "source": [
    "from truecolours_loader import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.transformations.panel.signature_based import SignatureTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e5fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from truecolours_loader import load_and_parse_by_disease_from_pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24eaa0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Patient : 100%|██████████| 2510/2510 [03:42<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting the loaded dataframe\n"
     ]
    }
   ],
   "source": [
    "df1,df2 = load_and_parse_by_disease_from_pickle(update_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651be15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d960117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchcde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CD,y_CD,X_UC,y_UC = load_for_binary_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7980d",
   "metadata": {},
   "source": [
    "### Signature"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0eb15a2c",
   "metadata": {},
   "source": [
    "X = pd.DataFrame({},columns = [k for k in X_UC[0].columns if k != 'response_date'])\n",
    "for Xi in X_UC:\n",
    "    Xi = Xi.dropna(axis=0, how='any')\n",
    "    X = X.append({k:Xi[k] for k in Xi.columns if k != 'response_date'},ignore_index=True)    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c16ce2a",
   "metadata": {},
   "source": [
    "# First build a very simple signature transform module\n",
    "signature_transform = SignatureTransformer(\n",
    "    window_name=\"global\",\n",
    "    sig_tfm=\"signature\",\n",
    "    depth=3,\n",
    ")\n",
    "j=57\n",
    "# The simply transform the stream data\n",
    "print(\"Raw data shape is: {}\".format(X.shape))\n",
    "train_signature_x = signature_transform.fit_transform(X.iloc[j:j+1])\n",
    "print(\"Signature shape is: {}\".format(train_signature_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b06c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_UC[0].plot(x='response_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2c3cb",
   "metadata": {},
   "source": [
    "### CDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.CubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc37d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c076877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_epochs=30):\n",
    "    train_X, train_y = X_UC,np.array([a[0]<2 and a[1]<2 for a in y_UC])\n",
    "\n",
    "    ######################\n",
    "    # input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "    # hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "    # output_channels=1 because we're doing binary classification.\n",
    "    ######################\n",
    "    model = NeuralCDE(input_channels=3, hidden_channels=8, output_channels=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    ######################\n",
    "    # Now we turn our dataset into a continuous path. We do this here via Hermite cubic spline interpolation.\n",
    "    # The resulting `train_coeffs` is a tensor describing the path.\n",
    "    # For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n",
    "    ######################\n",
    "    train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(train_X)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch_coeffs, batch_y = batch\n",
    "            pred_y = model(batch_coeffs).squeeze(-1)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {}   Training loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "    test_X, test_y = get_data()\n",
    "    test_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(test_X)\n",
    "    pred_y = model(test_coeffs).squeeze(-1)\n",
    "    binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "    prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "    proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "    print('Test Accuracy: {}'.format(proportion_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab467c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_X, train_y = X_UC,np.array([a[0]<2 and a[1]<2 for a in y_UC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f51ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55976ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num_timepoints=100):\n",
    "    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n",
    "\n",
    "    start = torch.rand(128) * 2 * math.pi\n",
    "    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos[:64] *= -1\n",
    "    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos += 0.01 * torch.randn_like(x_pos)\n",
    "    y_pos += 0.01 * torch.randn_like(y_pos)\n",
    "    ######################\n",
    "    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n",
    "    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n",
    "    ######################\n",
    "    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n",
    "    y = torch.zeros(128)\n",
    "    y[:64] = 1\n",
    "\n",
    "    perm = torch.randperm(128)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    ######################\n",
    "    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n",
    "    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise\n",
    "    # respectively.\n",
    "    ######################\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15445682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_demo,y_demo = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30df076",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_demo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571db2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_demo[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17507a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
